# Text2Loc Visionary - 多服务部署配置
# 支持开发、测试和生产环境

version: '3.8'

# 定义网络
networks:
  text2loc-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# 定义共享卷
volumes:
  text2loc-data:
    driver: local
  text2loc-logs:
    driver: local
  text2loc-checkpoints:
    driver: local
  redis-data:
    driver: local
  ollama-models:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local

# 服务定义
services:
  # Ollama模型服务 - 提供NLU和嵌入模型
  ollama:
    image: ollama/ollama:latest
    container_name: text2loc-ollama
    restart: unless-stopped
    networks:
      - text2loc-network
    ports:
      - "11434:11434"
    volumes:
      - ollama-models:/root/.ollama
      - ./deployment/ollama-models.txt:/etc/ollama/models.txt
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_KEEP_ALIVE=24h
      - OLLAMA_NUM_PARALLEL=2
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    command: >
      sh -c "
      echo '等待ollama服务启动...' &&
      sleep 10 &&
      if [ -f /etc/ollama/models.txt ]; then
        while IFS= read -r model; do
          if [ -n \"$$model\" ]; then
            echo '拉取模型: $$model' &&
            ollama pull $$model || echo '模型拉取失败: $$model'
          fi
        done < /etc/ollama/models.txt
      fi &&
      echo '模型准备完成，启动服务' &&
      ollama serve
      "
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Redis缓存服务
  redis:
    image: redis:7-alpine
    container_name: text2loc-redis
    restart: unless-stopped
    networks:
      - text2loc-network
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD:-text2loc_redis_pass}
      - REDIS_PORT=6379
    command: >
      redis-server
      --requirepass $${REDIS_PASSWORD}
      --appendonly yes
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "$${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Text2Loc Visionary API服务
  text2loc-api:
    build:
      context: ..
      dockerfile: deployment/Dockerfile
      target: ${DOCKER_TARGET:-cpu-runtime}
    container_name: text2loc-api
    restart: unless-stopped
    networks:
      - text2loc-network
    ports:
      - "${API_PORT:-8080}:8080"
    volumes:
      - text2loc-data:/app/data
      - text2loc-logs:/app/logs
      - text2loc-checkpoints:/app/checkpoints
      - ../config:/app/config:ro
    environment:
      # 服务配置
      - TEXT2LOC_PORT=8080
      - TEXT2LOC_HOST=0.0.0.0
      - TEXT2LOC_ENV=${TEXT2LOC_ENV:-production}

      # 模型服务配置
      - OLLAMA_URL=http://ollama:11434
      - OLLAMA_TIMEOUT=30
      - MOCK_MODE=${MOCK_MODE:-false}

      # 数据库配置
      - REDIS_URL=redis://redis:6379
      - REDIS_PASSWORD=${REDIS_PASSWORD:-text2loc_redis_pass}

      # 性能配置
      - CACHE_ENABLED=true
      - BATCH_SIZE=10
      - MAX_CACHE_SIZE=1000

      # 监控配置
      - ENABLE_METRICS=true
      - METRICS_PORT=9090
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

      # 安全配置
      - API_KEY=${API_KEY:-}
      - CORS_ORIGINS=${CORS_ORIGINS:-*}

      # 特征开关
      - ENABLE_ENHANCED_NLU=true
      - ENABLE_VECTOR_SEARCH=true
      - ENABLE_HYBRID_RETRIEVAL=true
    depends_on:
      ollama:
        condition: service_healthy
      redis:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G

  # Text2Loc前端服务（可选）
  text2loc-frontend:
    build:
      context: ../frontend
      dockerfile: Dockerfile
    container_name: text2loc-frontend
    restart: unless-stopped
    networks:
      - text2loc-network
    ports:
      - "${FRONTEND_PORT:-80}:80"
    environment:
      - API_URL=http://text2loc-api:8080
      - NODE_ENV=production
    depends_on:
      - text2loc-api
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80"]
      interval: 30s
      timeout: 5s
      retries: 3

  # Prometheus监控服务（可选）
  prometheus:
    image: prom/prometheus:latest
    container_name: text2loc-prometheus
    restart: unless-stopped
    networks:
      - text2loc-network
    ports:
      - "9090:9090"
    volumes:
      - prometheus-data:/prometheus
      - ./deployment/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    depends_on:
      - text2loc-api

  # Grafana监控面板（可选）
  grafana:
    image: grafana/grafana:latest
    container_name: text2loc-grafana
    restart: unless-stopped
    networks:
      - text2loc-network
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./deployment/grafana-dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./deployment/grafana-datasources:/etc/grafana/provisioning/datasources:ro
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    depends_on:
      - prometheus

  # Nginx反向代理（生产环境推荐）
  nginx:
    image: nginx:alpine
    container_name: text2loc-nginx
    restart: unless-stopped
    networks:
      - text2loc-network
    ports:
      - "${NGINX_PORT:-80}:80"
      - "${NGINX_SSL_PORT:-443}:443"
    volumes:
      - ./deployment/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./deployment/ssl:/etc/nginx/ssl:ro
      - text2loc-logs:/var/log/nginx
    depends_on:
      - text2loc-api
      - text2loc-frontend
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 5s
      retries: 3

# 开发环境覆盖配置
x-dev-override: &dev-override
  environment:
    - TEXT2LOC_ENV=development
    - MOCK_MODE=true
    - LOG_LEVEL=DEBUG
    - CACHE_ENABLED=false
  volumes:
    - ../:/app
    - ../logs:/app/logs
  deploy:
    resources:
      limits:
        cpus: '1'
        memory: 1G

# 测试环境覆盖配置
x-test-override: &test-override
  environment:
    - TEXT2LOC_ENV=test
    - MOCK_MODE=true
    - LOG_LEVEL=INFO
    - CACHE_ENABLED=true
  deploy:
    resources:
      limits:
        cpus: '2'
        memory: 2G

# 生产环境覆盖配置
x-prod-override: &prod-override
  environment:
    - TEXT2LOC_ENV=production
    - MOCK_MODE=false
    - LOG_LEVEL=WARNING
    - CACHE_ENABLED=true
  deploy:
    resources:
      limits:
        cpus: '4'
        memory: 4G
    restart_policy:
      condition: on-failure
      max_attempts: 3
      window: 120s

# 环境特定配置
profiles:
  # 开发环境 - 最小化服务
  development:
    services:
      ollama:
        <<: *dev-override
      text2loc-api:
        <<: *dev-override
      redis:
        <<: *dev-override

  # 测试环境 - 完整服务
  test:
    services:
      ollama:
        <<: *test-override
      text2loc-api:
        <<: *test-override
      redis:
        <<: *test-override

  # 生产环境 - 完整服务带监控
  production:
    services:
      ollama:
        <<: *prod-override
      text2loc-api:
        <<: *prod-override
      redis:
        <<: *prod-override
      prometheus:
      grafana:
      nginx:

  # 完整监控环境
  monitoring:
    services:
      prometheus:
      grafana:

  # 前端开发
  frontend:
    services:
      text2loc-frontend:
        environment:
          - API_URL=http://localhost:8080
          - NODE_ENV=development

# 使用说明：
# 1. 开发环境: docker-compose --profile development up
# 2. 测试环境: docker-compose --profile test up
# 3. 生产环境: docker-compose --profile production up
# 4. 完整环境: docker-compose up
#
# 环境变量配置（在.env文件中）：
# API_PORT=8080
# FRONTEND_PORT=80
# REDIS_PASSWORD=your_redis_password
# TEXT2LOC_ENV=production
# MOCK_MODE=false
# LOG_LEVEL=INFO
# API_KEY=your_api_key
# DOCKER_TARGET=cpu-runtime (或 gpu-runtime)
